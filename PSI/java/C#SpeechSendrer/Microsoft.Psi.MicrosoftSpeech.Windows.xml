<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.Psi.MicrosoftSpeech.Windows</name>
    </assembly>
    <members>
        <member name="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeech">
            <summary>
            Static helper methods.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeech.BuildIntentData(Microsoft.Speech.Recognition.SemanticValue)">
            <summary>
            Method to construct the IntentData (intents and entities) from
            a SemanticValue.
            </summary>
            <param name="semanticValue">The SemanticValue object.</param>
            <returns>An IntentData object containing the intents and entities.</returns>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeech.CreateSpeechRecognitionEngine(System.String,Microsoft.Psi.Speech.GrammarInfo[])">
            <summary>
            Creates a new speech recognition engine.
            </summary>
            <param name="language">The language for the recognition engine.</param>
            <param name="grammars">The grammars to load.</param>
            <returns>A new speech recognition engine object.</returns>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeech.ExtractEntities(Microsoft.Speech.Recognition.SemanticValue)">
            <summary>
            Method to extract all entities contained within a SemanticValue.
            </summary>
            <param name="semanticValue">The SemanticValue object.</param>
            <returns>The list of extracted entities.</returns>
        </member>
        <member name="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector">
            <summary>
            Component that performs grammar-based intent detection using the speech recognition engine from the Microsoft Speech Platform SDK.
            </summary>
            <remarks>
            Separate download and installation of the Microsoft Speech Platform runtime and language pack are required in order to use this component.
            - Click <a href="http://go.microsoft.com/fwlink/?LinkID=223568">here</a> to download the Microsoft Speech Platform runtime.
            - Click <a href="http://go.microsoft.com/fwlink/?LinkID=223569">here</a> to download the Microsoft Speech Platform language pack.
            </remarks>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.pipeline">
            <summary>
            The pipeline the component belongs to.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.speechRecognitionEngine">
            <summary>
            The Microsoft.Speech speech recognition engine.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector"/> class.
            </summary>
            <param name="pipeline">The Psi pipeline.</param>
            <param name="configurationFilename">The name of the configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.ReceiveGrammars">
            <summary>
            Gets the receiver for new grammars.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.ReceiveGrammarNames">
            <summary>
            Gets the receiver for new grammars (by name).
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.LoadGrammarCompleted">
            <summary>
            Gets the output stream of load grammar completed events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.SetGrammars(Microsoft.Psi.Message{System.Collections.Generic.IEnumerable{System.String}})">
            <summary>
            Replace grammars with given.
            </summary>
            <param name="srgsXmlGrammars">A collection of XML-format speech grammars that conform to the SRGS 1.0 specification.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.EnableGrammars(Microsoft.Psi.Message{System.String[]})">
            <summary>
            Enable all the grammars indicated by name, disabling all others.
            </summary>
            <param name="grammarNames">Speech grammars.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.DisableAllGrammars">
            <summary>
            Disable all of the grammars loaded on this recognition engine.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.Start(System.Action{System.DateTime})">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.Stop(System.DateTime,System.Action)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.Receive(System.String,Microsoft.Psi.Envelope)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector.CreateSpeechRecognitionEngine">
            <summary>
            Creates a new speech recognition engine.
            </summary>
            <returns>A new speech recognition engine object.</returns>
        </member>
        <member name="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetector"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
            <remarks>
            Use this to set the language for speech recognition. The language must be an installed Runtime
            Language for speech recognition. The Microsoft Speech Platform Runtime does not include any
            Runtime Languages for speech recognition. You must download and install a Runtime Language for
            each language in which you want to recognize speech. A Runtime Language includes the language model,
            acoustic model, and other data necessary to provision a speech engine to perform speech recognition
            in a particular language. For a list of supported Runtime Languages and to download them, see
            http://go.microsoft.com/fwlink/?LinkID=223569.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechIntentDetectorConfiguration.Grammars">
            <summary>
            Gets or sets the list of grammar files.
            </summary>
            <remarks>
            Use this to specify a set of grammar files that the recognizer should use for intent detection.
            Grammar files are XML-format files that conform to the
            <a href="http://go.microsoft.com/fwlink/?LinkId=201761">W3C Speech Recognition Grammar Specification (SRGS) Version 1.0</a>.
            </remarks>
        </member>
        <member name="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer">
             <summary>
             Component that performs speech recognition using the Microsoft Speech Platform SDK.
             </summary>
             <remarks>
             Separate download and installation of the Microsoft Speech Platform runtime and language pack are required in order to use this component.
             - Click <a href="http://go.microsoft.com/fwlink/?LinkID=223568">here</a> to download the Microsoft Speech Platform runtime.
             - Click <a href="http://go.microsoft.com/fwlink/?LinkID=223569">here</a> to download the Microsoft Speech Platform language pack.
            
             The originating times of speech recognition events emitted by this component are estimates. These are estimated in a couple of ways
             from the results that the underlying speech recognition engine returns. In the case of a final recognition result, we use the audio
             position offset of the recognized audio as reported by the recognition engine to compute an estimate of the originating time. For
             partial hypotheses, we use the engine's current offset into the audio stream to estimate the originating time.
             </remarks>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.inputAudioStream">
            <summary>
            Stream for buffering audio samples to send to the speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.lastPostedOriginatingTimes">
            <summary>
            The last originating time that was recorded for each output stream.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.speechRecognitionEngine">
            <summary>
            The Microsoft.Speech speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.streamStartTime">
            <summary>
            The implied stream start time.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.recognizeCompleteManualReset">
            <summary>
            Event to signal that the recognizer has been stopped.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The Psi pipeline.</param>
            <param name="configurationFilename">The name of the configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.ReceiveGrammars">
            <summary>
            Gets the receiver for new grammars.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.ReceiveGrammarNames">
            <summary>
            Gets the receiver for new grammars (by name).
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.PartialRecognitionResults">
            <summary>
            Gets the output stream of partial recognition results.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.IntentData">
            <summary>
            Gets the output stream of intents and entities.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.SpeechDetected">
            <summary>
            Gets the output stream of speech detected events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.SpeechHypothesized">
            <summary>
            Gets the output stream of speech hypothesized events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.SpeechRecognized">
            <summary>
            Gets the output stream of speech recognized events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.SpeechRecognitionRejected">
            <summary>
            Gets the output stream of speech recognition rejected events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.AudioSignalProblemOccurred">
            <summary>
            Gets the output stream of audio problem events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.AudioStateChanged">
            <summary>
            Gets the output stream of audio state change events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.RecognizeCompleted">
            <summary>
            Gets the output stream of recognize completed events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.AudioLevelUpdated">
            <summary>
            Gets the output stream of audio level updated events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.EmulateRecognizeCompleted">
            <summary>
            Gets the output stream of emulate recognize completed completed events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.LoadGrammarCompleted">
            <summary>
            Gets the output stream of load grammar completed events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.RecognizerUpdateReached">
            <summary>
            Gets the output stream of recognizer update reached events.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.SetGrammars(Microsoft.Psi.Message{System.Collections.Generic.IEnumerable{System.String}})">
            <summary>
            Replace grammars with given.
            </summary>
            <param name="srgsXmlGrammars">A collection of XML-format speech grammars that conform to the SRGS 1.0 specification.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.EnableGrammars(Microsoft.Psi.Message{System.String[]})">
            <summary>
            Enable all the grammars indicated by name, disabling all others.
            </summary>
            <param name="grammarNames">Speech grammars.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.DisableAllGrammars">
            <summary>
            Disable all of the grammars loaded on this recognition engine.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.Start(System.Action{System.DateTime})">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.Stop(System.DateTime,System.Action)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.Receive(Microsoft.Psi.Audio.AudioBuffer,Microsoft.Psi.Envelope)">
            <summary>
            Receiver for audio data.
            </summary>
            <param name="audio">A buffer containing the next chunk of audio data.</param>
            <param name="e">The message envelope for the audio data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.CreateSpeechRecognitionEngine">
            <summary>
            Creates a new speech recognition engine.
            </summary>
            <returns>A new speech recognition engine object.</returns>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnSpeechDetected(System.Object,Microsoft.Speech.Recognition.SpeechDetectedEventArgs)">
            <summary>
            Called when speech is detected.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnSpeechHypothesized(System.Object,Microsoft.Speech.Recognition.SpeechHypothesizedEventArgs)">
            <summary>
            Called whenever a partial recognition result is available.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnSpeechRecognized(System.Object,Microsoft.Speech.Recognition.SpeechRecognizedEventArgs)">
            <summary>
            Called when the final recognition result received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnRecognizeCompleted(System.Object,Microsoft.Speech.Recognition.RecognizeCompletedEventArgs)">
            <summary>
            Called when the engine finalizes the recognition operation.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnSpeechRecognitionRejected(System.Object,Microsoft.Speech.Recognition.SpeechRecognitionRejectedEventArgs)">
            <summary>
            Called when the engine is unable to match speech input to any of its enabled grammars.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.OnRecognizerUpdateReached(System.Object,Microsoft.Speech.Recognition.RecognizerUpdateReachedEventArgs)">
            <summary>
            Requested by `SetGrammars()` - now ready to update.
            </summary>
            <param name="sender">Event sender.</param>
            <param name="e">Event args (`UserToken` expected to contain grammars).</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.PostWithOriginatingTimeConsistencyCheck``1(Microsoft.Psi.Emitter{``0},``0,System.DateTime)">
            <summary>
            Posts a message to a stream while ensuring the consistency of the supplied originating time
            such that it cannot be before the originating time of the last posted message on the stream.
            If so, it will be adjusted accordingly.
            </summary>
            <remarks>
            Use this method when posting messages to output streams where the computed originating times of
            the messages are not guaranteed to be monotonically increasing, which is a requirement of Psi.
            </remarks>
            <typeparam name="T">The type of the output stream.</typeparam>
            <param name="stream">The stream on which to post.</param>
            <param name="data">The data to post.</param>
            <param name="originatingTime">The originating time of the data.</param>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.BuildSpeechRecognitionResult(Microsoft.Speech.Recognition.RecognitionResult)">
            <summary>
            Builds a SpeechRecognitionResult object from a RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A SpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer.BuildPartialSpeechRecognitionResult(Microsoft.Speech.Recognition.RecognitionResult)">
            <summary>
            Builds a SpeechRecognitionResult object from a partial RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A SpeechRecognitionResult object containing the partial recognition result.</returns>
        </member>
        <member name="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
            <remarks>
            Use this to set the language for speech recognition. The language must be an installed Runtime
            Language for speech recognition. The Microsoft Speech Platform Runtime does not include any
            Runtime Languages for speech recognition. You must download and install a Runtime Language for
            each language in which you want to recognize speech. A Runtime Language includes the language model,
            acoustic model, and other data necessary to provision a speech engine to perform speech recognition
            in a particular language. For a list of supported Runtime Languages and to download them, see
            http://go.microsoft.com/fwlink/?LinkID=223569.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration.Grammars">
            <summary>
            Gets or sets the list of grammar files.
            </summary>
            <remarks>
            Use this to specify a set of grammar files that the recognizer should use for speech recognition.
            Grammar files are XML-format files that conform to the
            <a href="http://go.microsoft.com/fwlink/?LinkId=201761">W3C Speech Recognition Grammar Specification (SRGS) Version 1.0</a>.
            At least one grammar is required in order to use the <see cref="T:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizer"/>.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration.BufferLengthInMs">
            <summary>
            Gets or sets the length of the recognizer's input stream buffer in milliseconds.
            </summary>
            <remarks>
            Audio arriving on the input stream will be stored in an internal buffer for the speech recognition
            engine to read as it is able. This buffer will block when full until the recognition engine is able
            to read from the buffer. Set this value to modify the length of the buffer, which is computed based
            on the length of audio to buffer in milliseconds and the audio input format. By default, a 1000 ms
            buffer is used. It is safe to leave this value unchanged.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.MicrosoftSpeech.MicrosoftSpeechRecognizerConfiguration.InputFormat">
            <summary>
            Gets or sets the expected input format of the audio stream.
            </summary>
            <remarks>
            Preferred input audio formats are 1-channel, 16-bit PCM samples. Use the
            <see cref="M:Microsoft.Psi.Audio.WaveFormat.Create16kHz1Channel16BitPcm"/> or
            <see cref="M:Microsoft.Psi.Audio.WaveFormat.Create16BitPcm(System.Int32,System.Int32)"/> static methods to create the appropriate
            <see cref="T:Microsoft.Psi.Audio.WaveFormat"/> object. If not specified, a default value of 16000 Hz is assumed.
            </remarks>
        </member>
    </members>
</doc>
