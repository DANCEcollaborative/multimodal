<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.Psi.CognitiveServices.Speech</name>
    </assembly>
    <members>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer">
            <summary>
            Component that performs speech recognition using the <a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech/">Microsoft Cognitive Services Azure Speech API</a>.
            </summary>
            <remarks>The component takes in a stream of audio and performs speech-to-text recognition. It works in conjunction with the
            <a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech/">Microsoft Cognitive Services Azure Speech API</a>
            and requires a subscription key in order to use. For more information, see the complete documentation for the
            <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/">Microsoft Cognitive Services Azure Speech API</a>.
            </remarks>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.speechRecognitionClient">
            <summary>
            The client that communicates with the cloud speech recognition service.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastPartialResult">
            <summary>
            The last partial recognition result.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastVADSpeechStartTime">
            <summary>
            The time the VAD last detected the start of speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastVADSpeechEndTime">
            <summary>
            The time the VAD last detected the end of speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastAudioContainingSpeechTime">
            <summary>
            The time the last audio input contained speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastVADSpeechTimeInterval">
            <summary>
            The time interval of the last detected speech segment.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastAudioOriginatingTime">
            <summary>
            The originating time of the most recently received audio packet.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastPostedOriginatingTimes">
            <summary>
            The last originating time that was recorded for each output stream.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastAudioContainedSpeech">
            <summary>
            A flag indicating whether the last audio packet received contained speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.currentQueue">
            <summary>
            Queue of current audio buffers for the pending recognition task.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.lastAudioBuffer">
            <summary>
            Last contiguous audio buffer collected pending recognition.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.conversationError">
            <summary>
            The last conversation error.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.fatalError">
            <summary>
            Flag to indicate that a fatal error has occurred.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configurationFilename">The component configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.PartialRecognitionResults">
            <summary>
            Gets the output stream of partial recognition results.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.PartialSpeechResponseEvent">
            <summary>
            Gets the output stream of PartialSpeechResponseEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.SpeechErrorEvent">
            <summary>
            Gets the output stream of SpeechErrorEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.SpeechResponseEvent">
            <summary>
            Gets the output stream of SpeechResponseEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.Dispose">
            <summary>
            Dispose method.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.ReceiveAsync(System.ValueTuple{Microsoft.Psi.Audio.AudioBuffer,System.Boolean},Microsoft.Psi.Envelope)">
            <summary>
            Receiver for the combined VAD signal and audio data.
            </summary>
            <param name="data">A message containing the combined VAD signal and audio data.</param>
            <param name="e">The message envelope.</param>
            <returns>The <see cref="T:System.Threading.Tasks.Task"/> representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.CreateSpeechRecognitionClient">
            <summary>
            Creates a new recognition client.
            </summary>
            <returns>A new speech recognition client object.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.OnResponseReceivedHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs)">
            <summary>
            Called when a final response is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.OnPartialResponseReceivedHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs)">
            <summary>
            Called when a partial response is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.OnConversationErrorHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs)">
            <summary>
            Called when an error is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.BuildSpeechRecognitionResult(Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult)">
            <summary>
            Builds a StreamingSpeechRecognitionResult object from a RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A StreamingSpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.BuildSpeechRecognitionResult(System.String,System.Nullable{System.Double})">
            <summary>
            Builds a StreamingSpeechRecognitionResult object for an empty recognition.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <param name="confidence">The confidence score (if any).</param>
            <returns>A StreamingSpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer.BuildPartialSpeechRecognitionResult(System.String,System.Nullable{System.Double})">
            <summary>
            Builds a partial StreamingSpeechRecognitionResult object from a partial text result returned by the recognizer.
            </summary>
            <param name="partialResult">The partial result from the recognizer.</param>
            <param name="confidence">The confidence score of the result (if any).</param>
            <returns>A StreamingSpeechRecognitionResult object containing the partial recognition result.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
            <remarks>
            Use this to set the locale for the speech recognition service. If not specified,
            this defaults to "en-us" (U.S. English). Other supported locales include "en-gb",
            "de-de", "es-es", "fr-fr", "it-it" and "zh-cn".
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration.SubscriptionKey">
            <summary>
            Gets or sets the subscription key.
            </summary>
            <remarks>
            This component uses the Azure Speech API to perform speech recognition. A Cognitive Services
            subscription is required in order to use this service. The <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/>
            authenticates with the service using a subscription key associated with the subcription. See
            https://azure.microsoft.com/en-us/try/cognitive-services/ for more information on obtaining a
            subscription.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration.InputFormat">
            <summary>
            Gets or sets the expected input format of the audio stream.
            </summary>
            <remarks>
            Currently, the only supported input audio format is 16000 Hz, 1-channel, 16-bit PCM.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizerConfiguration.Region">
            <summary>
            Gets or sets the region.
            </summary>
            <remarks>
            This is the region that is associated to the subscription key.
            </remarks>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer">
             <summary>
             Component that performs speech recognition using the <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech/">Microsoft Cognitive Services Bing Speech API</a>.
             </summary>
             <remarks>
             DEPRECATED - As the Bing Speech service will be retired soon, you can no longer
             obtain a new subscription key for this service. If you have previously obtained a subscription
             key for the Bing Speech service, then this key should continue to work with this component
             until the service is retired. If you do not have an existing subscription
             key for the Bing Speech service, please use the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> component
             instead. You may obtain a subscription key for the Azure Speech service here:
             https://azure.microsoft.com/en-us/try/cognitive-services/?api=speech-services.
            
             This component takes in a stream of audio and performs speech-to-text recognition. It works in conjunction with the
             <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech/">Microsoft Cognitive Services Bing Speech API</a>
             and requires a subscription key in order to use. For more information, see the complete documentation for the
             <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/speech/">Microsoft Cognitive Services Bing Speech API</a>.
             </remarks>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.speechRecognitionClient">
            <summary>
            The client that communicates with the cloud speech recognition service.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastPartialResult">
            <summary>
            The last partial recognition result.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastVADSpeechStartTime">
            <summary>
            The time the VAD last detected the start of speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastVADSpeechEndTime">
            <summary>
            The time the VAD last detected the end of speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastAudioContainingSpeechTime">
            <summary>
            The time the last audio input contained speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastVADSpeechTimeInterval">
            <summary>
            The time interval of the last detected speech segment.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastAudioOriginatingTime">
            <summary>
            The originating time of the most recently received audio packet.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastPostedOriginatingTimes">
            <summary>
            The last originating time that was recorded for each output stream.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastAudioContainedSpeech">
            <summary>
            A flag indicating whether the last audio packet received contained speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.currentQueue">
            <summary>
            Queue of current audio buffers for the pending recognition task.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.lastAudioBuffer">
            <summary>
            Last contiguous audio buffer collected pending recognition.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.conversationError">
            <summary>
            The last conversation error.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.fatalError">
            <summary>
            Flag to indicate that a fatal error has occurred.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configurationFilename">The component configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.PartialRecognitionResults">
            <summary>
            Gets the output stream of partial recognition results.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.PartialSpeechResponseEvent">
            <summary>
            Gets the output stream of PartialSpeechResponseEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.SpeechErrorEvent">
            <summary>
            Gets the output stream of SpeechErrorEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.SpeechResponseEvent">
            <summary>
            Gets the output stream of SpeechResponseEventArgs.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.Dispose">
            <summary>
            Dispose method.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.Start(System.Action{System.DateTime})">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.Stop(System.DateTime,System.Action)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.ReceiveAsync(System.ValueTuple{Microsoft.Psi.Audio.AudioBuffer,System.Boolean},Microsoft.Psi.Envelope)">
            <summary>
            Receiver for the combined VAD signal and audio data.
            </summary>
            <param name="data">A message containing the combined VAD signal and audio data.</param>
            <param name="e">The message envelope.</param>
            <returns>The <see cref="T:System.Threading.Tasks.Task"/> representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.CreateSpeechRecognitionClient">
            <summary>
            Creates a new recognition client.
            </summary>
            <returns>A new speech recognition client object.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.OnResponseReceivedHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs)">
            <summary>
            Called when a final response is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.OnPartialResponseReceivedHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs)">
            <summary>
            Called when a partial response is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.OnConversationErrorHandler(System.Object,Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs)">
            <summary>
            Called when an error is received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.BuildSpeechRecognitionResult(Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult)">
            <summary>
            Builds a StreamingSpeechRecognitionResult object from a RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A StreamingSpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.BuildSpeechRecognitionResult(System.String,System.Nullable{System.Double})">
            <summary>
            Builds a StreamingSpeechRecognitionResult object for an empty recognition.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <param name="confidence">The confidence score (if any).</param>
            <returns>A StreamingSpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer.BuildPartialSpeechRecognitionResult(System.String,System.Nullable{System.Double})">
            <summary>
            Builds a partial StreamingSpeechRecognitionResult object from a partial text result returned by the recognizer.
            </summary>
            <param name="partialResult">The partial result from the recognizer.</param>
            <param name="confidence">The confidence score of the result (if any).</param>
            <returns>A StreamingSpeechRecognitionResult object containing the partial recognition result.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration">
             <summary>
             Represents the configuration for the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer"/> component.
             </summary>
             <remarks>
             DEPRECATED - As the Bing Speech service will be retired soon, you can no longer
             obtain a new subscription key for this service. If you have previously obtained a subscription
             key for the Bing Speech service, then this key should continue to work with this component
             until the service is retired. If you do not have an existing subscription
             key for the Bing Speech service, please use the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> component
             instead. You may obtain a subscription key for the Azure Speech service here:
             https://azure.microsoft.com/en-us/try/cognitive-services/?api=speech-services.
            
             Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer"/> component.
             Refer to the properties in this class for more information on the various configuration options.
             </remarks>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
            <remarks>
            Use this to set the locale for the speech recognition service. If not specified,
            this defaults to "en-us" (U.S. English). Other supported locales include "en-gb",
            "de-de", "es-es", "fr-fr", "it-it" and "zh-cn".
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration.RecognitionMode">
            <summary>
            Gets or sets the speech recognition mode.
            </summary>
            <remarks>
            The speech recognition mode must be one of the values defined in the enumeration
            <see cref="T:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode"/>. The default value is <see cref="F:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode.Interactive"/>.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration.SubscriptionKey">
            <summary>
            Gets or sets the subscription key.
            </summary>
            <remarks>
            This component uses the Bing Speech API to perform speech recognition. A Cognitive Services
            subscription is required in order to use this service. The <see cref="T:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizer"/>
            authenticates with the service using a subscription key associated with the subcription.
            However, as the Bing Speech service will be retired soon, you can no longer
            obtain a new subscription key for this service. If you have previously obtained a subscription
            key for the Bing Speech service, then this key should continue to work with this component
            until the service is retired. If you do not have an existing subscription
            key for the Bing Speech service, please use the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.AzureSpeechRecognizer"/> component
            instead. You may obtain a subscription key for the Azure Speech service here:
            https://azure.microsoft.com/en-us/try/cognitive-services/?api=speech-services.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.BingSpeechRecognizerConfiguration.InputFormat">
            <summary>
            Gets or sets the expected input format of the audio stream.
            </summary>
            <remarks>
            Currently, the only supported input audio format is 16000 Hz, 1-channel, 16-bit PCM.
            </remarks>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage">
            <summary>
            Represents a message containing audio to be sent to the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> class.
            </summary>
            <remarks>
            This overload creates an empty <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> which is typically used to denote the end of the audio stream.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage.#ctor(Microsoft.Psi.Audio.WaveFormat)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> class.
            </summary>
            <param name="format">The format of the audio.</param>
            <remarks>
            This overload creates an <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> carrying the serialized format data.
            This should be sent once, before any audio data is sent to the service.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage.#ctor(System.Byte[])">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> class.
            </summary>
            <param name="data">An array of bytes containing the message data.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage.#ctor(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage"/> class.
            </summary>
            <param name="data">An array of bytes containing the message data.</param>
            <param name="offset">The offset into the array where the message data starts.</param>
            <param name="count">The number of bytes of data to include in the message.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AudioMessage.CreateRiffHeader(Microsoft.Psi.Audio.WaveFormat)">
            <summary>
            Creates a RIFF header for the supplied WaveFormat object.
            </summary>
            <param name="format">The WaveFormat object.</param>
            <returns>A byte array containing the RIFF header.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication">
            <summary>
            Provides methods to get a valid O-auth token. Adapted from the following sample code:
            https://docs.microsoft.com/en-us/azure/cognitive-services/speech/how-to/how-to-authentication.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication.FetchTokenUri">
            <summary>
            The token service URL.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication"/> class.
            </summary>
            <param name="subscriptionKey">The subscription key with which to request a token.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.Authentication.GetAccessToken">
            <summary>
            Gets the current valid token, fetching a new token if necessary.
            </summary>
            <returns>The valid token.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication">
            <summary>
            Provides methods to get a valid O-auth token. Adapted from the following sample code:
            https://docs.microsoft.com/en-us/azure/cognitive-services/speech/how-to/how-to-authentication.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication.FetchTokenUri">
            <summary>
            The token service URL.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication"/> class.
            </summary>
            <param name="subscriptionKey">The subscription key with which to request a token.</param>
            <param name="region">The region that is associated to the subscription key.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.AzureAuthentication.GetAccessToken">
            <summary>
            Gets the current valid token, fetching a new token if necessary.
            </summary>
            <returns>The valid token.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.IAuthentication">
            <summary>
            IAuthentication defines our interface for the different types of authentication.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.IAuthentication.GetAccessToken">
            <summary>
            Gets the access token from the auth provider using the supplied information.
            </summary>
            <returns>the access token.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.IAuthentication.Dispose">
            <summary>
            Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs">
            <summary>
            Represents the arguments of a partial speech response event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs"/> class.
            </summary>
            <param name="partialResult">The partial speech recognition result text.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.PartialSpeechResponseEventArgs.PartialResult">
            <summary>
            Gets the partial speech recognition result text.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult">
            <summary>
            Represents a speech recognition result.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult.#ctor(Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult"/> class.
            </summary>
            <param name="speechPhraseMessage">
            The speech.phrase message returned by the service.
            </param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult.RecognitionStatus">
            <summary>
            Gets the recognition status code.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult.Results">
            <summary>
            Gets the list of recognized phrases.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus">
            <summary>
            Represents the possible recognition status values returned by the service.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.Success">
            <summary>
            The recognition was successful and the DisplayText field is present.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.NoMatch">
            <summary>
            Speech was detected in the audio stream, but no words from the target language were matched.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.InitialSilenceTimeout">
            <summary>
            The start of the audio stream contained only silence, and the service timed out waiting for speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.BabbleTimeout">
            <summary>
            The start of the audio stream contained only noise, and the service timed out waiting for speech.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.Error">
            <summary>
            The recognition service encountered an internal error and could not continue.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionStatus.EndOfDictation">
            <summary>
            The service detected the end of dictation in dictation mode.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase">
            <summary>
            Represents a single recognized phrase alternate.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.#ctor(Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase"/> class.
            </summary>
            <param name="value">The N-best value representing the alternate.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.LexicalForm">
            <summary>
            Gets the lexical form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.DisplayText">
            <summary>
            Gets the display form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.InverseTextNormalizationResult">
            <summary>
            Gets the ITN form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.MaskedInverseTextNormalizationResult">
            <summary>
            Gets the masked ITN form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.RecognizedPhrase.Confidence">
            <summary>
            Gets the confidence score of this alternate.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus">
            <summary>
            Represents a set of error codes for the speech service.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpBadRequest">
            <summary>
            The client sent a WebSocket connection request that was incorrect.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpUnauthorized">
            <summary>
            The client did not include the required authorization information.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpForbidden">
            <summary>
            The client sent authorization information, but it was invalid.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpNotFound">
            <summary>
            The client attempted to access a URL path that is not supported.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpServerError">
            <summary>
            The service encountered an internal error and could not satisfy the request.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.HttpServiceUnavailable">
            <summary>
            The service was unavailable to handle the request.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.WebSocketNormalClosure">
            <summary>
            The service closed the WebSocket connection without an error.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.WebSocketProtocolError">
            <summary>
            The client failed to adhere to protocol requirements.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.WebSocketInvalidPayloadData">
            <summary>
            The client sent an invalid payload in a protocol message.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus.WebSocketServerError">
            <summary>
            The service encountered an internal error and could not satisfy the request.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage">
            <summary>
            Represents a speech.config message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.System">
            <summary>
            Gets or sets the system element of the speech.config message.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.Os">
            <summary>
            Gets or sets the os element of the speech.config message.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.Device">
            <summary>
            Gets or sets the device element of the speech.config message.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.SystemInfo">
            <summary>
            Represents the system element of the speech.config message.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.SystemInfo.Version">
            <summary>
            Gets the version of the speech SDK software used by the client.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.OsInfo">
            <summary>
            Represents the os element of the speech.config message.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.OsInfo.Platform">
            <summary>
            Gets the OS platform that hosts the application, for example, Windows, Android, iOS, or Linux.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.OsInfo.Name">
            <summary>
            Gets the OS product name, for example, Debian or Windows 10.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.OsInfo.Version">
            <summary>
            Gets the version of the OS in the form major.minor.build.branch.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.DeviceInfo">
            <summary>
            Represents the device element of the speech.config message.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.DeviceInfo.Manufacturer">
            <summary>
            Gets the device hardware manufacturer.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.DeviceInfo.Model">
            <summary>
            Gets the device model.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechConfigMessage.DeviceInfo.Version">
            <summary>
            Gets the device software version provided by the device manufacturer.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechEndDetectedMessage">
            <summary>
            Represents a speech.endDetected message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechEndDetectedMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechEndDetectedMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechEndDetectedMessage.Offset">
            <summary>
            Gets or sets the offset when the end of speech was detected in 100-nanosecond units from the start of audio.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs">
            <summary>
            Represents the arguments of a speech error event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs.#ctor(Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs"/> class.
            </summary>
            <param name="speechErrorCode">The error code.</param>
            <param name="speechErrorText">The error text.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs.SpeechErrorCode">
            <summary>
            Gets the speech error code.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechErrorEventArgs.SpeechErrorText">
            <summary>
            Gets the speech error text.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage">
            <summary>
            Represents a speech.fragment message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage.Text">
            <summary>
            Gets or sets the text of the fragment.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage.Offset">
            <summary>
            Gets or sets the offset (in 100-nanosecond units) when the phrase was recognized,
            relative to the start of the audio stream.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechFragmentMessage.Duration">
            <summary>
            Gets or sets the duration (in 100-nanosecond units) of this speech phrase.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage">
            <summary>
            Represents a speech.hypothesis message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage.Text">
            <summary>
            Gets or sets the text of the hypothesis.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage.Offset">
            <summary>
            Gets or sets the offset (in 100-nanosecond units) when the phrase was recognized,
            relative to the start of the audio stream.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechHypothesisMessage.Duration">
            <summary>
            Gets or sets the duration (in 100-nanosecond units) of this speech phrase.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage">
            <summary>
            Represents a speech.phrase message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.RecognitionStatus">
            <summary>
            Gets or sets the status of the recognition.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.DisplayText">
            <summary>
            Gets or sets the recognized phrase after capitalization, punctuation, and inverse-text-
            normalization have been applied and profanity has been masked with asterisks.
            The DisplayText field is present only if the RecognitionStatus field has the value Success.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.Offset">
            <summary>
            Gets or sets the offset (in 100-nanosecond units) at which the phrase was recognized,
            relative to the start of the audio stream.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.Duration">
            <summary>
            Gets or sets the duration (in 100-nanosecond units) of this speech phrase.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBest">
            <summary>
            Gets or sets the N-best list of top speech alternates.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue">
            <summary>
            Represents a speech alternate value.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue.Confidence">
            <summary>
            Gets or sets the confidence score of this alternate.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue.Lexical">
            <summary>
            Gets or sets the lexical form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue.ITN">
            <summary>
            Gets or sets the ITN form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue.MaskedITN">
            <summary>
            Gets or sets the masked ITN form of the recognized text.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechPhraseMessage.NBestValue.Display">
            <summary>
            Gets or sets the display form of the recognized text.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient">
            <summary>
            Provides a client for the Cognitive Services Speech service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.#ctor(Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode,System.String,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient"/> class.
            </summary>
            <param name="recognitionMode">The recognition mode to use.</param>
            <param name="language">The recognition language.</param>
            <param name="subscriptionKey">The speech service API key.</param>
            <param name="region">The speech service region associated to the subscription.</param>
        </member>
        <member name="E:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.OnResponseReceived">
            <summary>
            An event that is raised when a final speech recognition response has beeen received.
            </summary>
        </member>
        <member name="E:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.OnPartialResponseReceived">
            <summary>
            An event that is raised when a partial speech recognition response has beeen received.
            </summary>
        </member>
        <member name="E:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.OnConversationError">
            <summary>
            An event that is raised in response to a service error.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SetAudioFormat(Microsoft.Psi.Audio.WaveFormat)">
            <summary>
            Sets the format of the audio that will be sent to the service.
            </summary>
            <param name="audioFormat">The audio format.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SendAudioAsync(System.Byte[],System.Threading.CancellationToken)">
            <summary>
            Sends the next chunk of audio in the audio stream to the speech service.
            </summary>
            <param name="audioBytes">The raw audio.</param>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SendEndAudioAsync(System.Threading.CancellationToken)">
            <summary>
            Sends an empty audio packet to signal the end of the audio stream.
            </summary>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.InitializeConnectionAsync(System.Threading.CancellationToken)">
            <summary>
            Initializes the connection to the service and prepares it to receive audio for recognition.
            </summary>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.CloseConnectionAsync">
            <summary>
            Closes the connection to the service.
            </summary>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.ConnectAsync(System.Threading.CancellationToken)">
            <summary>
            Establishes a new web socket connection to the service.
            </summary>
            <param name="token">A task cancellation token.</param>
            <returns>
            A Task representing the asynchronous operation whose result will contain a new
            ClientWebSocket for the connection upon task completion.
            </returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SendSpeechConfigAsync(System.Threading.CancellationToken)">
            <summary>
            Sends the speech.config message to the service.
            </summary>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SendAudioFormatAsync(Microsoft.Psi.Audio.WaveFormat,System.Threading.CancellationToken)">
            <summary>
            Sends the audio format to the service. This needs to be the first audio message for any new connection.
            </summary>
            <param name="format">The audio format.</param>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.SendMessageAsync(Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage,System.String,System.Threading.CancellationToken)">
            <summary>
            Sends a message to the service.
            </summary>
            <param name="message">The message to send.</param>
            <param name="requestId">The request id associated with the message.</param>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.ReceiveMessageAsync(System.Net.WebSockets.WebSocket,System.String,System.Threading.CancellationToken)">
            <summary>
            Receives a single message from the service.
            </summary>
            <param name="webSocket">The connected WebSocket on which to listen for the message.</param>
            <param name="requestId">The request ID associated with the message.</param>
            <param name="token">A task cancellation token.</param>
            <returns>
            A Task representing the asynchronous operation whose result will contain the message
            received from the service upon task completion.
            </returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.ReceiveAsync(System.Net.WebSockets.WebSocket,System.String,System.Threading.CancellationToken)">
            <summary>
            Listens for messages received from the service and handles them appropriately.
            </summary>
            <param name="webSocket">The connected WebSocket on which to listen for the message.</param>
            <param name="requestId">The request ID associated with the conversation.</param>
            <param name="token">A task cancellation token.</param>
            <returns>A Task representing the asynchronous operation.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.RaiseTranslatedError(System.Net.WebSockets.WebSocketCloseStatus,System.String)">
            <summary>
            Translates a WebSocketCloseStatus and raises a conversation error if appropriate.
            </summary>
            <param name="status">The WebSocketCloseStatus code.</param>
            <param name="message">The associated WebSocket CloseStatusDescription.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.RaiseTranslateError(System.Net.WebSockets.WebSocketException)">
            <summary>
            Translates an exception and raises the appropriate conversation error event.
            </summary>
            <param name="error">The exception to translate.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.RaiseOnConversationError(Microsoft.Psi.CognitiveServices.Speech.Service.SpeechClientStatus,System.String)">
            <summary>
            Raises a ConversationError event.
            </summary>
            <param name="errorCode">The error code.</param>
            <param name="message">The message for the event.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechRecognitionClient.GetNewGuid">
            <summary>
            Generates a new random UUID in a format that may be used for connection or request IDs.
            </summary>
            <returns>The UUID string.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs">
            <summary>
            Represents the arguments of a speech response event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs.#ctor(Microsoft.Psi.CognitiveServices.Speech.Service.RecognitionResult)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs"/> class.
            </summary>
            <param name="result">The speech recognition result.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechResponseEventArgs.PhraseResponse">
            <summary>
            Gets the speech recognition result.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceBinaryMessage">
            <summary>
            Provides the base class for a binary message for the speech service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceBinaryMessage.#ctor(System.String,System.Byte[],System.Int32,System.Int32)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceBinaryMessage"/> class.
            </summary>
            <param name="path">The path header value.</param>
            <param name="data">An array containing the message payload.</param>
            <param name="offset">The offset into the array where the message payload starts.</param>
            <param name="count">The number of bytes to include in the message payload.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceBinaryMessage.ToString">
            <inheritdoc />
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceBinaryMessage.GetBytes">
            <inheritdoc />
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage">
            <summary>
            Provides the base class for a message for the speech service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.#ctor(System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage"/> class.
            </summary>
            <param name="path">The path header value.</param>
            <param name="contentType">The content type header value.</param>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.Headers">
            <summary>
            Gets the set of message headers.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.Path">
            <summary>
            Gets the message path header value.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.RequestId">
            <summary>
            Gets the request id header value.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.Deserialize(System.String)">
            <summary>
            Deserializes the raw text message from the service into its equivalent message type.
            </summary>
            <param name="message">The string representing the raw message.</param>
            <returns>The deserialized message object.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.GetBytes">
            <summary>
            Gets a byte array representation of the message.
            </summary>
            <returns>A byte array representation of the message.</returns>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceMessage.DeserializeBody(System.String,System.String)">
            <summary>
            Deserializes the JSON body of the message.
            </summary>
            <param name="path">The Path header value.</param>
            <param name="body">The JSON message body.</param>
            <returns>The deserialized message object.</returns>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceTextMessage">
            <summary>
            Provides the base class for a text message for the speech service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceTextMessage.#ctor(System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceTextMessage"/> class.
            </summary>
            <param name="path">The path header value.</param>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceTextMessage.ToString">
            <inheritdoc />
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechServiceTextMessage.GetBytes">
            <inheritdoc />
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechStartDetectedMessage">
            <summary>
            Represents a speech.startDetected message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechStartDetectedMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechStartDetectedMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.SpeechStartDetectedMessage.Offset">
            <summary>
            Gets or sets the the offset (in 100-nanosecond units) when speech was detected in the
            audio stream, relative to the start of the stream.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.TurnEndMessage">
            <summary>
            Represents a turn.end message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.TurnEndMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.TurnEndMessage"/> class.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage">
            <summary>
            Represents a turn.start message from the service.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage.Context">
            <summary>
            Gets or sets the context for the start of the turn.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage.ContextInfo">
            <summary>
            Represents the context for the start of the turn.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.CognitiveServices.Speech.Service.TurnStartMessage.ContextInfo.ServiceTag">
            <summary>
            Gets or sets a tag value that the service has associated with the turn.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode">
            <summary>
            Represents the available speech recognition modes.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode.Interactive">
            <summary>
            In interactive mode, a user makes short requests and expects the application to perform an action in response.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode.Conversation">
            <summary>
            In conversation mode, users are engaged in a human-to-human conversation.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.CognitiveServices.Speech.SpeechRecognitionMode.Dictation">
            <summary>
            In dictation mode, users recite longer utterances to the application for further processing.
            </summary>
        </member>
    </members>
</doc>
